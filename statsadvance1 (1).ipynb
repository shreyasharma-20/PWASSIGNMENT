{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Explain the properties of the F-distribution.\n",
        "\n",
        "Asymmetry: The F-distribution is skewed to the right and is not symmetrical\n",
        "\n",
        "Positive values: The F-distribution can only have positive values\n",
        "\n",
        "Parameters: The F-distribution is defined by two parameters: the degrees of freedom of the numerator (\\(m\\)) and the degrees of freedom of the denominator (\\(n\\))\n",
        "\n",
        "Approximates normal distribution: As the degrees of freedom for the numerator and the denominator increase, the F-distribution approaches the normal distribution\n",
        "\n",
        "Uses: The F-distribution is used to compare variances and in two-way Analysis of Variance\n",
        "\n",
        "F-statistic: The F-statistic is greater than or equal to zero\n",
        "\n",
        "Shape: The exact shape of the F-distribution depends on the degrees of freedom associated with the numerator and the denominator"
      ],
      "metadata": {
        "id": "5Lo8qGebxSii"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?\n",
        "\n",
        "The F-distribution is used in hypothesis testing, particularly in the analysis of variance (ANOVA) and the F-test, to compare the variances of two populations or samples\n",
        "\n",
        "## Hypothesis testing\n",
        "Scientists use hypothesis testing to statistically compare data from two or more populations. The F-distribution is used to determine if the F-value for a study indicates any statistically significant differences between two populations\n",
        "\n",
        "##ANOVA\n",
        "In ANOVA, the F-distribution is used to determine if the observed differences between sample means are statistically significant. This is done by using the ratio of two mean squares (variances).\n",
        "\n",
        "##F-test\n",
        "The F-test is a statistical test that uses the F-distribution to compare two variances by dividing them\n",
        "\n",
        "The F-distribution is appropriate for these tests because it's a probability distribution that arises frequently as the null distribution of a test statistic\n",
        "\n"
      ],
      "metadata": {
        "id": "HgVHCJnsx-rh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. What are the key assumptions required for conducting an F-test to compare the variances of two populations?\n",
        "\n",
        "\n",
        "When conducting an F-test to compare the variances of two populations, several key assumptions must be met:\n",
        "\n",
        "1)Independence: The samples must be independent of each other. This means that the selection or value of one sample does not affect the other.\n",
        "\n",
        "2)Normality: The data in both populations should be approximately normally distributed. While the F-test is somewhat robust to deviations from normality, severe departures can affect the validity of the test.\n",
        "\n",
        "3)Homogeneity of Variances: The variances of the two populations should be equal (homoscedasticity). The F-test specifically tests the null hypothesis that the two population variances are equal.\n",
        "\n",
        "4)Random Sampling: The samples should be randomly drawn from their respective populations to ensure that the results are generalizable.\n",
        "\n",
        "If these assumptions are met, the F-test can be appropriately applied to compare the variances of the two populations. If the assumptions are violated, alternative tests or transformations may be necessary to obtain valid results"
      ],
      "metadata": {
        "id": "zTNB_JgPywsT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. What is the purpose of ANOVA, and how does it differ from a t-test?\n",
        "\n",
        "The purpose of ANOVA (Analysis of Variance) is to determine whether there are statistically significant differences between the means of three or more groups. It assesses the variability within each group compared to the variability between the groups. If the variability between groups is greater than the variability within groups, it suggests that at least one group mean is different from the others.\n",
        "\n",
        "Key Differences Between ANOVA and t-tests:\n",
        "\n",
        "#Number of Groups:\n",
        "\n",
        "t-test: Used to compare the means of two groups.\n",
        "\n",
        "ANOVA: Used to compare the means of three or more groups.\n",
        "\n",
        "\n",
        "##Type of Comparison:\n",
        "\n",
        "t-test: Directly assesses whether the means of the two groups are different.\n",
        "\n",
        "ANOVA: Tests the hypothesis that all group means are equal without specifying which means are different. If ANOVA indicates significant differences, post-hoc tests can then identify which specific means differ.\n",
        "\n",
        "##Error Rate Control:\n",
        "\n",
        "t-test: Each test has its own Type I error rate, and conducting multiple t-tests increases the overall error rate.\n",
        "\n",
        "ANOVA: Controls the Type I error rate across all comparisons when assessing multiple groups, maintaining a consistent alpha level.\n",
        "Assumptions:\n",
        "\n",
        "Both tests assume normality and homogeneity of variances, but ANOVA can handle more complex experimental designs and is robust against some violations of these assumptions."
      ],
      "metadata": {
        "id": "JRmOJZtrzbWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Explain when and why you would use a one-way ANOVA instead of multiple t-tests when comparing more than two groups\n",
        "\n",
        "Using a one-way ANOVA instead of multiple t-tests when comparing more than two groups is important for several reasons:\n",
        "\n",
        "1)Control of Type I Error Rate: When you perform multiple t-tests, each test carries a risk of committing a Type I error (incorrectly rejecting the null hypothesis). If you conduct several t-tests, the overall risk of a Type I error increases. One-way ANOVA maintains the Type I error rate at a desired level (e.g., 0.05) across all comparisons, making it a more reliable method.\n",
        "\n",
        "2)Efficiency: One-way ANOVA allows for the comparison of all group means simultaneously in a single test. This is more efficient than performing multiple t-tests, as it requires less computational effort and time.\n",
        "\n",
        "3)Assumption Testing: ANOVA also provides a framework for assessing whether there are significant differences among group means, while allowing for the examination of underlying assumptions (like homogeneity of variances) in one go.\n",
        "\n",
        "4)Post-hoc Testing: If the ANOVA indicates significant differences, post-hoc tests can be conducted to determine which specific groups differ. This stepwise approach is clearer and more organized than multiple t-tests, where one would have to manually compare each pair.\n",
        "\n",
        "In summary, one-way ANOVA is preferred over multiple t-tests for comparing three or more groups because it controls the error rate, is more efficient, and allows for a structured analysis of differences among group means."
      ],
      "metadata": {
        "id": "NRAGy8Wizk1H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Compare the classical (frequentist) approach to ANOVA with the Bayesian approach. What are the key differences in terms of how they handle uncertainty, parameter estimation, and hypothesis testing?\n",
        "\n",
        "The classical (frequentist) approach to ANOVA and the Bayesian approach differ significantly in their handling of uncertainty, parameter estimation, and hypothesis testing. Here are the key differences:\n",
        "\n",
        "1. Handling Uncertainty:\n",
        "\n",
        "Frequentist Approach:\n",
        "\n",
        "Uncertainty is addressed through the concept of sampling distributions and p-values. The focus is on long-run frequencies of events under repeated sampling.\n",
        "Confidence intervals are used to provide a range of values within which the true parameter is expected to lie, based on the data at hand.\n",
        "Bayesian Approach:\n",
        "Uncertainty is quantified through probability distributions. Bayesian methods treat parameters as random variables with their own distributions (prior, posterior).\n",
        "The focus is on updating beliefs about the parameters based on observed data, leading to posterior distributions that reflect both prior information and data evidence.\n",
        "\n",
        "2. Parameter Estimation:\n",
        "\n",
        "Frequentist Approach:\n",
        "\n",
        "Parameters are fixed but unknown values. Estimation is done using point estimates (e.g., means) and intervals (confidence intervals) without incorporating prior beliefs.\n",
        "ANOVA focuses on estimating group means and variances based on sample data.\n",
        "Bayesian Approach:\n",
        "\n",
        "Parameters are treated as random variables, and estimation is done using the posterior distribution. The Bayesian approach provides a full distribution of parameter estimates rather than single point estimates.\n",
        "It incorporates prior distributions, which can reflect previous knowledge or beliefs about the parameters.\n",
        "3. Hypothesis Testing:\n",
        "\n",
        "Frequentist Approach:\n",
        "\n",
        "Hypothesis testing is done using null and alternative hypotheses, often assessed through p-values. A low p-value indicates significant evidence against the null hypothesis.\n",
        "The decision to reject or fail to reject the null hypothesis is made based on a predetermined significance level (e.g., Î± = 0.05).\n",
        "Bayesian Approach:\n",
        "\n",
        "Bayesian hypothesis testing uses the posterior probabilities to evaluate hypotheses. For instance, the Bayes Factor can be calculated to compare the strength of evidence for different hypotheses.\n",
        "Instead of a binary decision (reject/fail to reject), Bayesian analysis provides probabilities that reflect how much more likely one hypothesis is compared to another, allowing for a more nuanced interpretation."
      ],
      "metadata": {
        "id": "yJe6-A9Z3DtP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Question: You have two sets of data representing the incomes of two different professions1\n",
        "# Profession A2 [48, 52, 55, 60, 62]\n",
        "# Profession B2 [45, 50, 55, 52, 47] Perform an F-test to determine if the variances of the two professions'\n",
        "# incomes are equal. What are your conclusions based on the F-test?\n",
        "\n",
        "# Task2 Use Python to calculate the F-statistic and p-value for the given data.\n",
        "\n",
        "# Objective2 Gain experience in performing F-tests and interpreting the results in terms of variance comparison\n",
        "# New Section"
      ],
      "metadata": {
        "id": "24ZZQ4aU3h-r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTPdCMlpxQae",
        "outputId": "9347c872-4916-4cf5-a594-973360cbe25c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-statistic: 2.089171974522293\n",
            "p-value: 0.24652429950266966\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Data for the two professions\n",
        "profession_A = [48, 52, 55, 60, 62]\n",
        "profession_B = [45, 50, 55, 52, 47]\n",
        "\n",
        "# Calculate the variances\n",
        "var_A = np.var(profession_A, ddof=1)\n",
        "var_B = np.var(profession_B, ddof=1)\n",
        "\n",
        "# Calculate the F-statistic\n",
        "F_statistic = var_A / var_B\n",
        "\n",
        "# Degrees of freedom\n",
        "df_A = len(profession_A) - 1\n",
        "df_B = len(profession_B) - 1\n",
        "\n",
        "# Calculate the p-value\n",
        "p_value = stats.f.sf(F_statistic, df_A, df_B)  # Right-tail test\n",
        "\n",
        "# Output the results\n",
        "print(f\"F-statistic: {F_statistic}\")\n",
        "print(f\"p-value: {p_value}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Question2 Conduct a one-way ANOVA to test whether there are any statistically significant differences in average heights between three different regions with the following data1\n",
        "\n",
        "# Region A2 [160, 162, 165, 158, 164]\n",
        "\n",
        "# Region B2 [172, 175, 170, 168, 174]\n",
        "\n",
        "# Region C2 [180, 182, 179, 185, 183]\n",
        "\n",
        "# New Section\n",
        "\n",
        "#Task2 Write Python code to perform the one-way ANOVA and interpret the results\n",
        "# Objective2 Learn how to perform one-way ANOVA using Python and interpret F-statistic and p-value"
      ],
      "metadata": {
        "id": "Yl8P7sLb4JLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "\n",
        "# Data for the three regions\n",
        "region_A = [160, 162, 165, 158, 164]\n",
        "region_B = [172, 175, 170, 168, 174]\n",
        "region_C = [180, 182, 179, 185, 183]\n",
        "\n",
        "# Perform one-way ANOVA\n",
        "F_statistic, p_value = stats.f_oneway(region_A, region_B, region_C)\n",
        "\n",
        "# Output the results\n",
        "print(f\"F-statistic: {F_statistic}\")\n",
        "print(f\"p-value: {p_value}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZuJUEHZ39a_",
        "outputId": "f0abe6b9-7157-4c5a-8bb9-ec9e0789851b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F-statistic: 67.87330316742101\n",
            "p-value: 2.870664187937026e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yaLu1w3V4lbl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}